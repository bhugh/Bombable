{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhugh/Bombable/blob/master/MIDI_File_Frequency_Fingerprint_Generator_v2_x.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YGiwvWWxiwy"
      },
      "source": [
        "# **FREQUENCY FINGERPRINTS**\n",
        "**With this notebook you can generate a FREQUENCY FINGERPRINT of a musical work.** The Frequency Fingerprint totals up all the pitches of notes of the work, weighted by the number of times each note was played and how long it was held. You can then both hear and see the results.  Average & most commonly played pitches are also shown.\n",
        "\n",
        "This notebook comes pre-loaded with Frequency Fingerprint analysis of the three movements of the Moonlight Sonata - which give some really interesting insights into the Sonata. So first, scroll down to view and listen to those samples.\n",
        "\n",
        "Second: Generating your own Frequency Fingerprints from one or more MIDI files is as easy as 1-2-3:\n",
        "\n",
        "1. ***Initialize*** - Click the *RUN* button just under that heading to get the code ready to run\n",
        "2. ***Upload the files*** - Click the *RUN* button here and an upload box will appear.\n",
        "3. ***Process the files*** - After you have uploaded the files and put them in the order you like, click \"Process Files\" and you will see the result!\n",
        "\n",
        "To process more files, go back to [Step #2. Upload the MIDI Files](#scrollTo=Upload_the_MIDI_Files) and press the PLAY button (on the left) again.\n",
        "\n",
        "*>>>>More details about Frequency Fingerprints and this project down at the bottom: [What is a Frequency Fingerprint - and Why](#scrollTo=Frequency_Fingerprints_results_what_you_are_hearing_and_seeing), [Details & Credits](#scrollTo=Frequency_Fingerprints_results_what_you_are_hearing_and_seeing)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Initialize\n",
        "***>>>>Click the \"Play\" button just below to the left. This will run the needed initialization routines. Wait until it completes - it may take a minute or so.***\n",
        "\n",
        "\n",
        "*   *Usually this section doesn't need to run again unless the session terminates or crashes.  If you receive error messages when uploading or processing files, you can try Initializing again to solve them.*"
      ],
      "metadata": {
        "id": "tV3kcruKOcLa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OKuEMXzsxiw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586bd776-cf56-436f-9f8d-f0c63dd7e75e",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fluidsynth is already the newest version (2.2.5-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: mido in /usr/local/lib/python3.10/dist-packages (1.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mido) (24.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-pyaudio is already the newest version (0.2.11-1.3ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.26.4)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mido>=1.1.16->pretty_midi) (24.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: pyfluidsynth in /usr/local/lib/python3.10/dist-packages (1.3.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyfluidsynth) (1.26.4)\n",
            "inited\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "!apt install fluidsynth\n",
        "!pip install mido\n",
        "!apt install python3-pyaudio\n",
        "!pip install librosa\n",
        "!pip install pretty_midi  # Install required library\n",
        "!pip install pydub\n",
        "#!apt install fluidsynth # Install fluidsynth for MIDI playback\n",
        "!pip install pyfluidsynth\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2 # Copy a soundfont\n",
        "\n",
        "import numpy as np\n",
        "from IPython.display import Audio, display\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import periodogram\n",
        "from scipy.signal.windows import hamming\n",
        "from google.colab import files\n",
        "#from music21 import converter, instrument\n",
        "#import fluidsynth\n",
        "import time\n",
        "\n",
        "#import sounddevice as sd\n",
        "#sd.query_devices()\n",
        "# %%capture\n",
        "\n",
        "#initialize default values for sliders & checkboxes etc\n",
        "histogram_checkbox_value = True\n",
        "spectrum_checkbox_value = False\n",
        "waveform_s_checkbox_value = False\n",
        "waveform_f_checkbox_value = False\n",
        "duration = 2\n",
        "smoothness_slider_value = 5\n",
        "filenames = []\n",
        "sample_rate = 44100 # Sampling rate in Hz (for fingerprint audio files)\n",
        "\n",
        "print (\"inited\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Process MIDI (Utility Cell 1)"
      ],
      "metadata": {
        "id": "O1iLYIViOLK0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "xtQYFZQ4xiw4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# this cell based on code by u/CptanPanic - https://www.reddit.com/r/classicalmusic/comments/1gpcjtd/comment/lwqda1g/\n",
        "\n",
        "import mido\n",
        "\n",
        "def midi_number_to_name(note_number, column = False):\n",
        "\n",
        "    \"\"\"Convert a MIDI note number to its corresponding note name.\"\"\"\n",
        "\n",
        "    # Define the note names and their corresponding MIDI numbers\n",
        "\n",
        "    note_names = [\n",
        "\n",
        "        'C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'\n",
        "\n",
        "    ]\n",
        "    note_names_column = [\n",
        "\n",
        "        'C ', 'C#', 'D ', 'D#', 'E ', 'F ', 'F#', 'G ', 'G#', 'A ', 'A#', 'B '\n",
        "\n",
        "    ]\n",
        "    if (column):\n",
        "        note_names = note_names_column\n",
        "\n",
        "    # Calculate the octave and the note name\n",
        "\n",
        "    octave = (note_number // 12) - 1 # MIDI note 0 is C-1\n",
        "\n",
        "    note_name = note_names[round(note_number) % 12]\n",
        "\n",
        "    return f\"{note_name}{octave}\"\n",
        "\n",
        "def calculate_note_frequency_counts(midi_file_path):\n",
        "\n",
        "    # Load the MIDI file\n",
        "\n",
        "    mid = mido.MidiFile(midi_file_path)\n",
        "\n",
        "    # List to store note frequency count\n",
        "    count = 0\n",
        "    ticks_per_beat = mid.ticks_per_beat\n",
        "\n",
        "    note_frequency_count = [0] * 128\n",
        "    note_values = []\n",
        "    # Iterate through all the tracks in the MIDI file\n",
        "\n",
        "    for track in mid.tracks:\n",
        "        notes_sounding = [-1] * 128\n",
        "        count = 0\n",
        "        elapsed_time_ticks = 0\n",
        "\n",
        "        for msg in track:\n",
        "            #print(msg)\n",
        "            count += 1\n",
        "            #if count > 250:\n",
        "            #    break\n",
        "            #if count < 250:\n",
        "            #    print(msg)\n",
        "\n",
        "        # Check if the message is a note_on message\n",
        "            elapsed_time_ticks += msg.time\n",
        "\n",
        "            if msg.type == 'note_on' and msg.velocity > 0:\n",
        "                #for now we are counting each note struck in the histogram\n",
        "                #With midi, calculating the actual time each note is held gets\n",
        "                #pretty tricky\n",
        "                #note_frequency_count[msg.note] += 1\n",
        "                notes_sounding[msg.note] = elapsed_time_ticks\n",
        "                note_values.append(msg.note)\n",
        "\n",
        "            if msg.type == 'note_off' or ( msg.type == 'note_on'and msg.velocity == 0 ):\n",
        "                if notes_sounding[msg.note] >= 0 and elapsed_time_ticks - notes_sounding[msg.note] >= 0:\n",
        "                    time_played_ticks = elapsed_time_ticks - notes_sounding[msg.note]\n",
        "                    real_played_ticks = time_played_ticks\n",
        "                    if  time_played_ticks > 10*ticks_per_beat:\n",
        "                        time_played_ticks = 10*ticks_per_beat\n",
        "                    note_frequency_count[msg.note] += time_played_ticks\n",
        "                    notes_sounding[msg.note] = -1\n",
        "                    #if count < 250:\n",
        "                    #    print (msg.note, real_played_ticks, time_played_ticks, note_frequency_count[msg.note])\n",
        "\n",
        "\n",
        "    # Calculate the average note\n",
        "\n",
        "    if note_values:\n",
        "\n",
        "        average_note = sum(note_values) / len(note_values)\n",
        "        out1 =  (str.format(\"Average note: MIDI Note #{:.2f} - {}{:+.2f} cents - {:.2f}hz\", average_note, midi_number_to_name(round(average_note)),average_note-round(average_note),calculate_note_frequency(average_note)))\n",
        "        weighted_ave = weighted_average(note_frequency_count)\n",
        "        out3 =  (str.format(\"Weighted Average note: MIDI Note #{:.2f} - {}{:+.2f} cents - {:.2f}hz\", weighted_ave, midi_number_to_name(round(weighted_ave)),weighted_ave-round(weighted_ave), calculate_note_frequency(weighted_ave)))\n",
        "        most_common = index_of_largest_list_member(note_frequency_count)\n",
        "        out2 =  (str.format(\"Most commonly played note: MIDI Note #{} - {} - {:.2f}hz\", most_common, midi_number_to_name(most_common),calculate_note_frequency(most_common)))\n",
        "        display(HTML(\"<p><b>\" + out1 + \"</b></p>\"))\n",
        "        display(HTML(\"<p><b>\" + out2 + \"</b></p>\"))\n",
        "        display(HTML(\"<p><b>\" + out3 + \"</b></p>\"))\n",
        "\n",
        "    return note_frequency_count, out1, out2, out3, average_note, weighted_ave, most_common\n",
        "\n",
        "def calculate_white_note_frequencies():\n",
        "\n",
        "    # List to store note frequencies\n",
        "\n",
        "    note_frequencies = []\n",
        "    note_labels = []\n",
        "\n",
        "    for f in range(21,109,1):\n",
        "        note_freq = 440 * 2**((f-69)/12)\n",
        "        note_name = midi_number_to_name(f)\n",
        "        note_frequencies.append( note_freq)\n",
        "        if note_name.find('#') <= 0:\n",
        "\n",
        "            if (note_name.find('C') >= 0):\n",
        "              note_name=note_name[0:2]\n",
        "            else:\n",
        "              note_name=note_name[0:1]\n",
        "            if (note_name.find('A') >= 0):\n",
        "                note_name += f\"\\n{note_freq:.0f}\"\n",
        "            note_labels.append(note_name)\n",
        "        else:\n",
        "          note_labels.append('#')\n",
        "    #print (note_frequencies)\n",
        "    #print (note_labels)\n",
        "\n",
        "    return note_frequencies, note_labels\n",
        "\n",
        "def calculate_note_frequencies():\n",
        "\n",
        "  # List to store note frequencies\n",
        "\n",
        "  note_frequencies = [0] * 128 # this needs to correspond exactly to list note_frequency_count\n",
        "\n",
        "  for f in range(0,127,1):\n",
        "      note_frequencies[f] = 440 * 2**((f-69)/12)\n",
        "\n",
        "  return note_frequencies\n",
        "\n",
        "\n",
        "def calculate_note_frequency(note):\n",
        "\n",
        "    return 440 * 2**((note-69)/12)\n",
        "\n",
        "\n",
        "def largest_nonzero_index(lst):\n",
        "    for i in range(len(lst) - 1, -1, -1):\n",
        "        if lst[i] != 0:\n",
        "            return i\n",
        "    return 0\n",
        "\n",
        "def index_of_largest_list_member(lst):\n",
        "    max = 0\n",
        "    save = None\n",
        "    for i in range(0, len(lst) - 1, 1):\n",
        "        if lst[i] > max:\n",
        "            max = lst[i]\n",
        "            save = i\n",
        "\n",
        "    return save\n",
        "\n",
        "def weighted_average(lst):\n",
        "    total = 0\n",
        "    divisor = 0\n",
        "    for i in range(0, len(lst) - 1, 1):\n",
        "        total += i*lst[i]\n",
        "        divisor += lst[i]\n",
        "\n",
        "    if divisor == 0:\n",
        "        divisor = 1\n",
        "\n",
        "    return total/divisor\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Results (Utility Cell 2)"
      ],
      "metadata": {
        "id": "cX1dZ124OGfw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "TFLWVGH-xiw7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "#using FluidSynth\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def create_results(input_midi_file):\n",
        "    global duration, sample_rate, smoothness  # Declare duration and sample_rate as global\n",
        "\n",
        "    #out = widgets.Output()\n",
        "    #display(out)\n",
        "\n",
        "    #display(HTML(\"<p><h3>Choose which elements to display:</h3>\"))\n",
        "    display(HTML(\"<p>&nbsp;</p>\"))\n",
        "    display(HTML(\"<p>&nbsp;</p>\"))\n",
        "    display(HTML(\"<p><b>=========================================================================================</b></p>\"))\n",
        "    display(HTML(\"<p><b>========  RESULTS  =========================================================================</b></p>\"))\n",
        "    display(HTML(\"<p><b>=========================================================================================</b></p>\"))\n",
        "    display(HTML(\"<p>&nbsp;</p>\"))\n",
        "    display(HTML(\"<p>Input file:\" + input_midi_file + \"</p>\"))\n",
        "    display(HTML(\"<p>&nbsp;</p>\"))\n",
        "    frequencies = calculate_note_frequencies()\n",
        "    amplitudes, msg1, msg2, msg3, average_note, weighted_ave, most_common = calculate_note_frequency_counts(input_midi_file)\n",
        "    print()\n",
        "\n",
        "    max_note = largest_nonzero_index(amplitudes)\n",
        "    max_freq = frequencies[max_note]\n",
        "    max_frequency_to_display_on_plots = max_freq\n",
        "    #max_frequency_to_display_on_plots = max(frequencies) * 1.5\n",
        "\n",
        "    # Time array\n",
        "    time = np.linspace(0, duration, int(sample_rate * duration))\n",
        "\n",
        "    # Generate the signal by summing sine waves of different frequencies\n",
        "    #signal = np.sum([amplitudes[i] * np.sin(2 * np.pi * frequencies[i] * time) for i in range(len(frequencies))], axis=0)\n",
        "    #fact = np.sqrt(10)/2 # if we want to double the perceptual sound,  doubling amplitude doesn't quite do it.  We need to increase by a factor of sqrt(10) rather than a factor of 2.  So adding this factor in should make the needed adjustment.\n",
        "    #This is however meaningless because it just multiplies all values in the signal by a certain value\n",
        "    #later we are going to normalize it, anyway...\n",
        "    # So sqrt (amplitudes[i]) (or smoothness = 1/2) is probably the \"most accurate\" representation of the various magnitudes, as perceived by the human ear\n",
        "    # Because perceived loudness is roughly proportional to the \"power\" which is the square of the magnitude\n",
        "    if smoothness<=0:\n",
        "      smoothness = 0.00001\n",
        "\n",
        "    signal = np.sum([amplitudes[i]**smoothness * np.sin(2 * np.pi * frequencies[i] * time) for i in range(len(frequencies))], axis=0)\n",
        "    #print (\"SIGNL\",len(signal), signal.size, signal.ndim,signal.shape,signal.base)\n",
        "    # Normalize the signal\n",
        "    signal = signal / np.max(np.abs(signal))*0.2 # These are quite dissonant so seem to come across better if a bit quieter.\n",
        "    signal = fade_in_out_audio (signal, fade_duration=0.02, sr=sample_rate)\n",
        "    #print (\"SIGNL\",len(signal), signal.size, signal.ndim,signal.shape,signal.base)\n",
        "    save_signal=signal.copy() # saving w/o the fade in/out\n",
        "\n",
        "    signal = fade_in_out_audio (signal, fade_duration=0.02, sr=sample_rate)\n",
        "\n",
        "    audio = Audio(data=signal, rate=sample_rate, normalize=False)\n",
        "    display(audio)\n",
        "\n",
        "    # Create a button widget\n",
        "    button = widgets.Button(description=\"Process and Play\")\n",
        "\n",
        "    # Define a function to be executed when the button is clicked\n",
        "    def on_button_clicked(b):\n",
        "      # Clear previous output\n",
        "      clear_output()\n",
        "\n",
        "      # Get the MIDI file path (you'll need to define this)\n",
        "      midi_file_path = input_midi_file\n",
        "\n",
        "      # Process and play the MIDI file\n",
        "      #process_and_play_midi(midi_file_path)\n",
        "      midi_play_widget(input_midi_file)\n",
        "\n",
        "    # Attach the function to the button's click event\n",
        "    button.on_click(on_button_clicked)\n",
        "\n",
        "    # Display the button\n",
        "    display(button)\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    # Create a button\n",
        "    download_button = widgets.Button(description=\"Download MIDI File\")\n",
        "\n",
        "    # Define the function to be executed when the button is clicked\n",
        "    def on_button_clicked(b):\n",
        "      files.download(input_midi_file)\n",
        "      #print (\"The MIDI file was downloaded...\")\n",
        "      #display(HTML(download_link(input_midi_file)))\n",
        "\n",
        "    # Attach the function to the button's click event\n",
        "    download_button.on_click(on_button_clicked)\n",
        "\n",
        "    # Display the button\n",
        "    display(download_button)\n",
        "    \"\"\"\n",
        "\n",
        "    # Create an Audio object and display it\n",
        "\n",
        "\n",
        "    #This is not interesting for Frequency Fingerprint purposes\n",
        "    #Plot the spectrogram\n",
        "    #plt.figure(figsize=(14, 4))\n",
        "    #plt.specgram(signal, Fs=sample_rate)\n",
        "    #plt.title('Spectrogram')\n",
        "    #plt.xlabel('Time (s)')\n",
        "    #plt.ylabel('Frequency (Hz)')\n",
        "    #plt.ylim(0, max_frequency_to_display_on_plots)\n",
        "    #plt.show()\n",
        "\n",
        "    #This is not interesting for Frequency Fingerprint purposes\n",
        "    #NFFT = 1024\n",
        "    #noverlap = NFFT // 2\n",
        "    #plt.figure(figsize=(14, 4))\n",
        "    #plt.specgram(signal, Fs=sample_rate, window=hamming(NFFT), NFFT=NFFT, noverlap=noverlap)\n",
        "    #plt.title('Spectrogram (hamming)')\n",
        "    #plt.xlabel('Time (s)')\n",
        "    #plt.ylabel('Frequency (Hz)')\n",
        "    #plt.ylim(0, max_frequency_to_display_on_plots)\n",
        "    #plt.show()\n",
        "\n",
        "    xticks, xlabels = calculate_white_note_frequencies()\n",
        "\n",
        "    ##################################################################\n",
        "    # HISTOGRAM of note frequencies\n",
        "    frequencies = [f if f > 0 else 1e-10 for f in frequencies]\n",
        "    bar_widths = [(frequencies[i+1] - frequencies[i])/2 for i in range(len(frequencies)-1)]\n",
        "    bar_widths.append(bar_widths[-1])  # Add the last bar width\n",
        "\n",
        "    import re\n",
        "    nice_filename=os.path.splitext(os.path.basename(input_midi_file))[0]\n",
        "    nice_filename = nice_filename.replace('-', ' ').replace('_', ' ')\n",
        "    nice_filename = re.sub(r'\\(\\d+\\)$', '', nice_filename)\n",
        "\n",
        "    if histogram_checkbox.value:\n",
        "      fig, ax = plt.subplots() # Create a figure and an axes object\n",
        "      fig.set_size_inches(20, 9)\n",
        "      ax.bar(frequencies, amplitudes, width=bar_widths, align='center')  # Use ax to plot\n",
        "      ax.set_xlabel('Note/Frequency (Hz)\\nFREQUENCY FINGERPRINT HISTOGRAM')\n",
        "      ax.set_ylabel('Duration Count (MIDI ticks)')\n",
        "      plt.title(msg1 + \"\\n\" + msg3 + \"\\n\" + msg2 + \"\\n\\n\\n\\n\")\n",
        "      fig.text(0.091,0.022, nice_filename, ha='center', va='bottom', fontsize=10)\n",
        "      #ax.set_xlim([0, max_frequency_to_display_on_plots])  # Limit to positive frequencies\n",
        "      ax.set_xlim([40, 4200])  # Limit to positive frequencies\n",
        "      ax.set_xscale('log') # Set xscale on the axes object\n",
        "      ax.set_xticks(xticks, labels=xlabels)\n",
        "\n",
        "      maxa = np.max(amplitudes)\n",
        "      top_border_y = ax.get_ylim()[1]\n",
        "\n",
        "      ################ Add AVERAGE\n",
        "      ave_frq= calculate_note_frequency(average_note)\n",
        "      plt.annotate(\n",
        "          \"Ave\",\n",
        "          xy=(ave_frq, top_border_y),  # Arrow tip at bin center and slightly above bin height\n",
        "          xytext=(ave_frq, top_border_y*1.03),  # Arrow tail at bin center and further above\n",
        "          arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3\", color=\"green\", linewidth=2),\n",
        "          color=\"green\",\n",
        "          ha='center' # Add this line to center the text horizontally\n",
        "      )\n",
        "\n",
        "      ################ Add WEIGHTED AVERAGE\n",
        "      ave_frq= calculate_note_frequency(weighted_ave)\n",
        "      plt.annotate(\n",
        "          \"W. Ave\",\n",
        "          xy=(ave_frq, top_border_y),\n",
        "          xytext=(ave_frq, top_border_y*1.06),\n",
        "          arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3\", color=\"red\", linewidth=2),\n",
        "          color=\"red\",\n",
        "          ha='center' # Add this line to center the text horizontally\n",
        "      )\n",
        "\n",
        "      ########################## Standard DEVIATION\n",
        "      sd = std_dev_binned(amplitudes)\n",
        "      sd_frq_low= calculate_note_frequency(weighted_ave-sd)\n",
        "      sd_frq_high= calculate_note_frequency(weighted_ave+sd)\n",
        "      #display(HTML(f\"SD!!!!!!!!!!!!! sd: {sd}, sd_frq: {sd_frq_low}, sd_frq: {sd_frq_high}\"))\n",
        "      # Create a bracket-like annotation\n",
        "      plt.annotate(\n",
        "          \"\",  # Empty string for no text\n",
        "          xy=(sd_frq_high, top_border_y ),  # Starting point of the bracket\n",
        "          xytext=(sd_frq_low, top_border_y),  # Ending point of the bracket\n",
        "          #arrowprops=dict(arrowstyle='-[, widthB=2.0, lengthB=0.5', lw=2.0, color='black')\n",
        "          arrowprops=dict(arrowstyle=\"-\", connectionstyle=\"arc3\", color=\"red\", linewidth=1),\n",
        "          va='center', ha='center',\n",
        "          color=\"red\"\n",
        "      )\n",
        "      plt.annotate(\n",
        "          \"SD\",  # Empty string for no text\n",
        "          xy=(sd_frq_high, top_border_y*.99 ),  # Starting point of the bracket\n",
        "          xytext=(sd_frq_low, top_border_y*1.03),  # Ending point of the bracket\n",
        "          #arrowprops=dict(arrowstyle='-[, widthB=2.0, lengthB=0.5', lw=2.0, color='black')\n",
        "          arrowprops=dict(arrowstyle=\"-\", connectionstyle=\"arc3\", color=\"none\", linewidth=1),\n",
        "          va='center', ha='center',\n",
        "          color=\"red\"\n",
        "      )\n",
        "\n",
        "\n",
        "      ################ Add MOST COMMON\n",
        "      ave_frq= calculate_note_frequency(most_common)\n",
        "      plt.annotate(\n",
        "          \"Mode\",\n",
        "          xy=(ave_frq, top_border_y),  # Arrow tip at bin center and slightly above bin height\n",
        "          xytext=(ave_frq, top_border_y*1.09),  # Arrow tail at bin center and further above\n",
        "          arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3\", color=\"blue\", linewidth=2),\n",
        "          color=\"blue\",\n",
        "          ha='center' # Add this line to center the text horizontally\n",
        "      )\n",
        "\n",
        "      # Calculate the cumulative frequencies\n",
        "      cumulative_freq = np.cumsum(amplitudes)\n",
        "\n",
        "      # Find the median bin index\n",
        "      median_bin_index = np.searchsorted(cumulative_freq, cumulative_freq[-1] / 2, side='right')\n",
        "\n",
        "      median_frq = frequencies[median_bin_index]\n",
        "      plt.annotate(\n",
        "          \"Median\",\n",
        "          xy=(median_frq, top_border_y),  # Arrow tip at bin center and slightly above bin height\n",
        "          xytext=(median_frq, top_border_y*1.12),  # Arrow tail at bin center and further above\n",
        "          arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3\", color=\"orange\", linewidth=2),\n",
        "          color=\"orange\",\n",
        "          ha='center' # Add this line to center the text horizontally\n",
        "      )\n",
        "\n",
        "      ################################################\n",
        "      # for the MOVIE\n",
        "      #\n",
        "      # Save plot as NumPy array and convert to RGB directly:\n",
        "       # Adjust layout to prevent clipping\n",
        "      fig.tight_layout()\n",
        "      fig.subplots_adjust(bottom=0.1, top=.75) #for more control\n",
        "      fig.canvas.draw()\n",
        "      image_data = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
        "      image_data = image_data.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n",
        "      image_data = image_data[:, :, :3].copy()  # Create a copy for RGB data\n",
        "\n",
        "      #image = plt.savefig(format='png')  # Convert the figure to an image\n",
        "      image_list.append(image_data)\n",
        "\n",
        "      from PIL import Image\n",
        "      Image.fromarray(image_data).save(f\"/content/temp/image{len(image_list)}.png\")\n",
        "\n",
        "      plt.show()\n",
        "\n",
        "      print()\n",
        "\n",
        "      #plt.imshow(image_data)  # Display a generic image\n",
        "\n",
        "\n",
        "    ##################################################################\n",
        "    # FFT POWER of Fingerprint\n",
        "    frequencies_proc = np.fft.fftfreq(len(time), 1/sample_rate)\n",
        "    magnitude = np.fft.fft(signal)\n",
        "    height = np.abs(magnitude)\n",
        "    power = np.abs(magnitude) ** 2\n",
        "\n",
        "    # Plot the periodogram\n",
        "    #fig=plt.figure(figsize=(14, 4))\n",
        "    #p = plt.plot(frequencies_proc, power)\n",
        "    #plt.title('Histogram of Weighted Frequencies')\n",
        "    #plt.xlabel('Frequency [Hz]')\n",
        "    #plt.ylabel('Power')\n",
        "    #plt.xlim([0, max_frequency_to_display_on_plots])  # Limit to positive frequencies\n",
        "    ##fig.set_xscale('log')\n",
        "    #lt.show()\n",
        "    #xticks = [27.5, 33,41,49,65,82,97,131,165,196,262,330,392,523,659,784,1046,1318,1568,2092,2637,3136,4184]\n",
        "    #xlabels = ['A0', 'C1\\n33','E1', 'G1', 'C2\\n65','E2','G2', 'C3\\n131','E3','G3', 'C4\\n262','E4','G4', 'C5\\n523','E6','G5', 'C6\\n1047','E6', 'G6','C7\\n2093','E7','G7', 'C8\\n4186']\n",
        "\n",
        "\n",
        "    if spectrum_checkbox.value:\n",
        "      fig, ax = plt.subplots() # Create a figure and an axes object\n",
        "      fig.set_size_inches(20, 5)\n",
        "      ax.plot(frequencies_proc, power)  # Use ax to plot\n",
        "      ax.set_xlabel('Note/Frequency (Hz)\\nFREQUENCY FINGERPRINT SPECTRUM')\n",
        "      ax.set_ylabel('Power')\n",
        "      plt.title(msg1 + \"\\n\" + msg3 + \"\\n\" + msg2 + \"\\n\")\n",
        "      fig.text(0.51, -0.1, os.path.basename(input_midi_file), ha='center', va='bottom', fontsize=8)\n",
        "      #ax.set_xlim([0, max_frequency_to_display_on_plots])  # Limit to positive frequencies\n",
        "      ax.set_xlim([40, 4200])  # Limit to positive frequencies\n",
        "      ax.set_xscale('log') # Set xscale on the axes object\n",
        "      ax.set_xticks(xticks, labels=xlabels)\n",
        "      plt.show()\n",
        "\n",
        "      print()\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    #This is usefull to see exactly what amplitudes were added to the Fingerprint, but\n",
        "    #the power graph (above) is a better representation of what we actually hear\n",
        "    if spectrum_checkbox.value:\n",
        "      fig, ax = plt.subplots() # Create a figure and an axes object\n",
        "      fig.set_size_inches(20, 5)\n",
        "      ax.plot(frequencies_proc, height)  # Use ax to plot\n",
        "      ax.set_xlabel('Note/Frequency (Hz)\\nFREQUENCY FINGERPRINT SPECTRUM')\n",
        "      ax.set_ylabel('Magnitude')\n",
        "      plt.title(msg1 + \"\\n\" + msg3 + \"\\n\" + msg2 + \"\\n\")\n",
        "      fig.text(0.51, -0.1, os.path.basename(input_midi_file), ha='center', va='bottom', fontsize=8)\n",
        "      #ax.set_xlim([0, max_frequency_to_display_on_plots])  # Limit to positive frequencies\n",
        "      ax.set_xlim([40, 4200])  # Limit to positive frequencies\n",
        "      ax.set_xscale('log') # Set xscale on the axes object\n",
        "      ax.set_xticks(xticks, labels=xlabels)\n",
        "      plt.show()\n",
        "\n",
        "      print()\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "     ##################################################################\n",
        "     # WAVEFORM of FINGERPRINT\n",
        "\n",
        "    if waveform_s_checkbox.value:\n",
        "      # Plot the waveform\n",
        "      plt.figure(figsize=(20, 4))\n",
        "      plt.plot(time[1000:5000], signal[1000:5000]) # Plotting a subset of the signal for better visibility\n",
        "      #plt.plot(time, signal)\n",
        "      plt.xlabel('Time (s) \\n Segment of Waveform of Frequency Fingerprint')\n",
        "      plt.ylabel('Amplitude')\n",
        "      plt.show()\n",
        "\n",
        "      print()\n",
        "\n",
        "    if waveform_f_checkbox.value:\n",
        "      # Plot the waveform\n",
        "      plt.figure(figsize=(20, 4))\n",
        "      plt.plot(time, signal) # Plotting a subset of the signal for better visibility\n",
        "      #plt.plot(time, signal)\n",
        "      plt.xlabel('Time (s) \\n Full Waveform of Frequency Fingerprint')\n",
        "      plt.ylabel('Amplitude')\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "    #FluidSynth.play_midi(input_midi_file)\n",
        "    #FluidSynth.play_midi()\n",
        "    #import fluidsynth\n",
        "    #import time\n",
        "    #from IPython.display import Audio\n",
        "    #from music21 import converter, instrument\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Set up FluidSynth MIDI player\n",
        "    #fl = fluidsynth.Synth()\n",
        "    ##sfid = fl.sfload(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\")\n",
        "    #fl.program_select(0, sfid, 0, 0)\n",
        "\n",
        "    # Load MIDI file as a music21 stream\n",
        "    #s = converter.parse(input_midi_file)\n",
        "    # Get all instruments\n",
        "    #parts = instrument.partitionByInstrument(s)\n",
        "\n",
        "    # For each instrument...\n",
        "    #if parts: # file has instrument parts\n",
        "    #  notes_to_parse = parts.parts[0].recurse()\n",
        "    #else: # file has notes in a flat structure\n",
        "    #  notes_to_parse = s.flat.notes\n",
        "\n",
        "    # Render the MIDI stream as audio\n",
        "    #audio_data = []\n",
        "    #for event in notes_to_parse:\n",
        "    #  if hasattr(event, 'pitch'):\n",
        "    #    fl.noteon(0, event.pitch.midi, int(event.volume.velocity))\n",
        "    #    audio_data.extend(fl.get_samples(int(event.duration.quarterLength * 44100)))\n",
        "    #    fl.noteoff(0, event.pitch.midi)\n",
        "    # Normalize audio data and play it in the notebook\n",
        "    #audio_data = np.array(audio_data, dtype=\"int16\")\n",
        "    #audio_data = audio_data / (2**15 - 1)\n",
        "    #a2 = Audio(audio_data, rate=44100)\n",
        "    #display(a2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #import tinysoundfont\n",
        "    import time\n",
        "    import sys\n",
        "    import pandas as pd\n",
        "    from google.colab import files\n",
        "    #files.download(input_midi_file)\n",
        "    #print (\"The MIDI file has been downloaded to your download dir\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def download_link(filename):\n",
        "      \"\"\"Generates a HTML link to download a file.\"\"\"\n",
        "      with open(filename, 'rb') as f:\n",
        "        file_content = f.read()\n",
        "      b64 = file_content.encode('base64').decode()\n",
        "      payload = f'<a download=\"{filename}\" href=\"data:text/csv;base64,{b64}\" target=\"_blank\">Download {filename}</a>'\n",
        "      return payload\n",
        "\n",
        "    \"\"\"\n",
        "    # THIS CAN BE MADE OPTION/CHECK BOX\n",
        "    # Display the list of chromatic notes & amplitudes\n",
        "    print ()\n",
        "    print (\"  *************************************\")\n",
        "    print (\"  **********Weighted Count*************\")\n",
        "    print (\"  *************************************\")\n",
        "    print ()\n",
        "    vals = 0\n",
        "    for i in range(max_note + 1):\n",
        "      if amplitudes[i] > 0:\n",
        "        vals += 1\n",
        "      if (vals > 0):\n",
        "        out =str.format(\"    Note #{:3} - {:3s} - {:5.0f}hz: {:7}\", i, midi_number_to_name(i,column=True),frequencies[i],amplitudes[i])\n",
        "        print (out)\n",
        "    print()\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #print(\"RETURNING SIGNAL_SAVED\")\n",
        "    display(HTML(\"<p>&nbsp;</p>\"))\n",
        "    return save_signal\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "#import cupy as np\n",
        "import scipy.signal as signal\n",
        "import scipy.signal.windows as ssw\n",
        "\n",
        "def fade_in_out_audio (audio, fade_duration=0.05, sr=44100):\n",
        "\n",
        "  # Smooth the ends using a window function\n",
        "  #fade_duration = 0.1  # Duration of fade in seconds\n",
        "  fade_samples = int(fade_duration * sr)  # Number of samples for fade\n",
        "\n",
        "  # Create a fade-in/fade-out window\n",
        "  window = ssw.hann(2 * fade_samples)\n",
        "  fade_in = window[:fade_samples]\n",
        "  fade_out = window[fade_samples:]\n",
        "\n",
        "  # Apply fade-in to the beginning\n",
        "  audio[:fade_samples] *= fade_in\n",
        "\n",
        "  # Apply fade-out to the end\n",
        "  audio[-fade_samples:] *= fade_out\n",
        "\n",
        "  return audio\n",
        "\n",
        "def overlap_audio (audio1, audio2, overlap_duration=0.5, sr=44100):\n",
        "\n",
        "  # Smooth the ends using a window function\n",
        "  #fade_duration = 0.1  # Duration of fade in seconds\n",
        "  fade_samples = int(overlap_duration * sr)  # Number of samples for fade\n",
        "\n",
        "  # Create a fade-in/fade-out window\n",
        "  #window = ssw.hann(2 * fade_samples)\n",
        "  #window = ssw.hamming(2 * fade_samples)\n",
        "  #fade_in = window[:fade_samples]\n",
        "  #fade_out = window[fade_samples:]\n",
        "\n",
        "  # Create power function ramp for fade-in and fade-out\n",
        "  fade_in = np.linspace(0, 1, fade_samples)**0.5\n",
        "  fade_out = np.linspace(1, 0, fade_samples)**0.5\n",
        "\n",
        "  # Apply fade-in to the beginning\n",
        "  audio2[:fade_samples] *= fade_in\n",
        "\n",
        "  # Apply fade-out to the end\n",
        "  audio1[-fade_samples:] *= fade_out\n",
        "\n",
        "  merge = audio1[-fade_samples:] + audio2[:fade_samples]\n",
        "\n",
        "  retaudio = np.concatenate([audio1[:-fade_samples], merge, audio2[fade_samples:]])\n",
        "\n",
        "  return retaudio\n",
        "\n",
        "def add_silent_audio (audio, duration=0.5, sr=44100):\n",
        "\n",
        "  silent_samples = int(duration * sr)  # Number of samples for silence\n",
        "\n",
        "\n",
        "  # Create power function ramp for fade-in and fade-out\n",
        "  silence = np.linspace(0, 0, silent_samples)\n",
        "\n",
        "\n",
        "  retaudio = np.concatenate([audio,silence])\n",
        "\n",
        "  return retaudio\n",
        "\n",
        "### Returns SD in 'indexes' of the array\n",
        "def std_dev_binned(amplitudes):\n",
        "  # Calculate bin edges\n",
        "  bin_edges = np.arange(len(amplitudes) + 1)  # [0, 1, 2, 3, 4, 5] for this example\n",
        "\n",
        "  # Calculate bin midpoints\n",
        "  bin_midpoints = (bin_edges[:-1] + bin_edges[1:]) / 2  # [0.5, 1.5, 2.5, 3.5, 4.5]\n",
        "\n",
        "  # Calculate weighted mean\n",
        "  weighted_mean = np.average(bin_midpoints, weights=amplitudes)\n",
        "\n",
        "  # Calculate weighted variance\n",
        "  variance = np.average((bin_midpoints - weighted_mean)**2, weights=amplitudes)\n",
        "\n",
        "  # Calculate standard deviation\n",
        "  std_dev = np.sqrt(variance)\n",
        "\n",
        "  return std_dev\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIDI routines (Utility Cell 3)"
      ],
      "metadata": {
        "id": "leHn2Q9Bpoou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import pretty_midi\n",
        "import fluidsynth\n",
        "#import pyfluidsynth\n",
        "from IPython.display import Audio, display\n",
        "#from fluidsynth import Synth # import Synth from fluidsynth\n",
        "\n",
        "def midi_play_widget(midi_file_path):\n",
        "  \"\"\"Plays a MIDI file in the notebook.\n",
        "\n",
        "  Args:\n",
        "      midi_file_path (str): Path to the MIDI file.\n",
        "  \"\"\"\n",
        "\n",
        "  # Load the MIDI file using pretty_midi\n",
        "  midi_data = pretty_midi.PrettyMIDI(midi_file_path)\n",
        "\n",
        "  # Synthesize audio from MIDI data using fluidsynth\n",
        "  # Adjust the sample rate if needed\n",
        "  fs = fluidsynth.Synth() # initialize Synth\n",
        "  fs.start()\n",
        "\n",
        "  soundfont_path = \"/content/FluidR3_GM.sf2\"  # Update if you saved it elsewhere\n",
        "  sfid = fs.sfload(soundfont_path)\n",
        "\n",
        "  fs.program_select(0, sfid, 0, 0)  # Select the desired soundfont and instrument\n",
        "  #midi_data.fluidsynth\n",
        "\n",
        "  audio_data = midi_data.synthesize() # Use fluidsynth to generate audio data\n",
        "\n",
        "  # Stop fluidsynth\n",
        "  fs.delete()\n",
        "\n",
        "  # Create and display an Audio widget for playback\n",
        "  display(Audio(audio_data, rate=44100))\n",
        "\n"
      ],
      "metadata": {
        "id": "cJwiDLxck33-",
        "cellView": "form"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z07k3zZBxiw2"
      },
      "source": [
        "# 2. Upload the MIDI Files\n",
        "When you run the cell below, you'll be able to choose a MIDI file - or several - to process.  \n",
        "\n",
        "***>>>> CLICK \"PLAY\" JUST BELOW TO THE LEFT***\n",
        "\n",
        "***>>>> THEN LOOK FOR THE \"CHOOSE FILES\" BUTTON AND CLICK IT***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# @title\n",
        "variable_name = \"\"\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, Video, FileLink\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "from google.colab import files\n",
        "from contextlib import contextmanager\n",
        "import tempfile\n",
        "from moviepy.editor import *\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "\n",
        "###############################################################\n",
        "# CHECKBOXES\n",
        "#\n",
        "display(HTML(\"<p><h3>Choose which elements to display:</h3>\"))\n",
        "\n",
        "\n",
        "\n",
        "histogram_checkbox = widgets.Checkbox(description='Show Histogram of Pitch Tallies', width = '800px', overflow_x='auto')\n",
        "\n",
        "spectrum_checkbox = widgets.Checkbox(description='Show Power Spectrum Graph Rof Fingerprint')\n",
        "waveform_s_checkbox = widgets.Checkbox(description='Show Waveform Segment of Fingerprint')\n",
        "waveform_f_checkbox = widgets.Checkbox(description='Show Full Waveform of Fingerprint')\n",
        "\n",
        "histogram_checkbox.value = histogram_checkbox_value\n",
        "spectrum_checkbox.value = spectrum_checkbox_value\n",
        "waveform_s_checkbox.value = waveform_s_checkbox_value\n",
        "waveform_f_checkbox.value = waveform_f_checkbox_value\n",
        "\n",
        "explanation0 = widgets.HTML(\n",
        "    value='<p style=\"line-height: 1.1;\"><i>If you want to see in more detail how the Histogram is converted into the audible Fingerprint, you can check the options for the Power Spectrum and Waveforms of the Fingerprint</i></p>'\n",
        ")\n",
        "\n",
        "\n",
        "histogram_checkbox.layout.width = '800px'\n",
        "spectrum_checkbox.layout.width = '800px'\n",
        "waveform_s_checkbox.layout.width = '800px'\n",
        "waveform_f_checkbox.layout.width = '800px'\n",
        "\n",
        "\n",
        "\n",
        "# Create a container Box with padding\n",
        "container0 = widgets.VBox(\n",
        "    [histogram_checkbox, spectrum_checkbox, waveform_s_checkbox, waveform_f_checkbox, explanation0],\n",
        "    layout=widgets.Layout(\n",
        "        padding='0px 0px 0px 80px',  # Apply padding to the container\n",
        "        width='900px',\n",
        "        #display='flex',  # Enable flexbox layout\n",
        "        #justify_content='flex-start'  # Align content to the left\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "#slider.layout.width = '600px'\n",
        "#slider.layout.margin_left = '20em'\n",
        "\n",
        "display(container0)  # Display the styled container\n",
        "\n",
        "\n",
        "# Display checkboxes\n",
        "#display(histogram_checkbox, spectrum_checkbox, waveform_s_checkbox, waveform_f_checkbox)\n",
        "\n",
        "def spectrum_changed(change):\n",
        "      #update the spectrum variable\n",
        "      spectrum_checkbox.value = change['new']\n",
        "      #print(change['new'])\n",
        "      pass # or some other action\n",
        "def histogram_changed(change):\n",
        "      #update the histogram variable\n",
        "      histogram_checkbox.value = change['new']\n",
        "      #print(change)\n",
        "      pass # or some other action\n",
        "def waveform_f_changed(change):\n",
        "      #update the waveform variable\n",
        "      waveform_f_checkbox.value = change['new']\n",
        "      #print(change)\n",
        "      pass # or some other action\n",
        "def waveform_s_changed(change):\n",
        "      #update the histogram variable\n",
        "      waveform_s_checkbox.value = change['new']\n",
        "      #print(change)\n",
        "      pass # or some other action\n",
        "spectrum_checkbox.observe(spectrum_changed, names='value')\n",
        "waveform_f_checkbox.observe(waveform_f_changed, names='value')\n",
        "waveform_s_checkbox.observe(waveform_s_changed, names='value')\n",
        "histogram_checkbox.observe(histogram_changed, names='value')\n",
        "\n",
        "\n",
        "##########################################\n",
        "# SLIDER - SMOOTHNESS\n",
        "#\n",
        "\n",
        "display(HTML(\"<p><h3>Fine-tune the sound:</h3>\"))\n",
        "# Create the slider\n",
        "slider = widgets.FloatSlider(\n",
        "    value=smoothness_slider_value,  # Initial value\n",
        "    min=-5,\n",
        "    max=100,\n",
        "    step=0.1,  # Step size\n",
        "    description='Smoothness:',\n",
        "    readout_format='.1f',\n",
        "    layout=widgets.Layout(width = '80%'),  # Changed to keyword argument\n",
        ")\n",
        "\n",
        "explanation = widgets.HTML(\n",
        "    value='<p style=\"line-height: 1.1;\"><i>Smoothness=0 is most realistic, keeping loudness of all pitches in exact proportion to the tally of notes as seen in the Histogram. Increasing Smoothness brings out the most prominent notes and de-emphasizes others - which is more to the point of a Frequency Fingerprint and often sounds better. </P><p style=\"line-height: 1.1;\">If you are getting phaser type effects increasing smoothness will reduce or eliminate them.</P><p style=\"line-height: 1.1;\">When fine-tuning a Fingerprint you can turn on the Fingerprint Power Spectrum and Waveform graphs to see how your changes are affecting the sound.</i></p>'\n",
        ")\n",
        "# Create a container Box with padding\n",
        "container = widgets.VBox(\n",
        "    [slider, explanation],\n",
        "    layout=widgets.Layout(\n",
        "        margin='0px 0px 0px 80px',  # Apply padding to the container\n",
        "        width='900px',\n",
        "        #display='flex',  # Enable flexbox layout\n",
        "        #justify_content='flex-start'  # Align content to the left\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "#slider.layout.width = '600px'\n",
        "#slider.layout.margin_left = '20em'\n",
        "\n",
        "display(container)  # Display the styled container\n",
        "\n",
        "# Display the slider widget\n",
        "#display(slider) # Display the slider separately\n",
        "\n",
        "##########################################\n",
        "# SLIDER - DURATION\n",
        "#\n",
        "\n",
        "display(HTML(\"<p><h3>Choose the length of the fingerprint (seconds):</h3>\"))\n",
        "# Create the slider\n",
        "slider2 = widgets.FloatSlider(\n",
        "    value=duration,  # Initial value\n",
        "    min=0.05,\n",
        "    max=10.05,\n",
        "    step=0.05,  # Step size\n",
        "    description='Length:',\n",
        "    readout_format='.2f',\n",
        "    layout=widgets.Layout(width = '80%'),  # Changed to keyword argument\n",
        ")\n",
        "\n",
        "explanation2 = widgets.HTML(\n",
        "    value='<p style=\"line-height: 1.1;\"></p>'\n",
        ")\n",
        "# Create a container Box with padding\n",
        "container2 = widgets.VBox(\n",
        "    [slider2, explanation2],\n",
        "    layout=widgets.Layout(\n",
        "        margin='0px 0px 0px 80px',  # Apply padding to the container\n",
        "        width='900px',\n",
        "        #display='flex',  # Enable flexbox layout\n",
        "        #justify_content='flex-start'  # Align content to the left\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "#slider.layout.width = '600px'\n",
        "#slider.layout.margin_left = '20em'\n",
        "\n",
        "display(container2)  # Display the styled container\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#SELECT A MIDI FILE OR FILES FROM YOUR LOCAL DIRECTORY\n",
        "#uploaded = files.upload(\"/content/MIDI Files/\")\n",
        "\n",
        "# Capture stdout\n",
        "#old_stdout = sys.stdout\n",
        "#sys.stdout = io.StringIO()\n",
        "\n",
        "#############################################################\n",
        "# CHOOSE FILES\n",
        "\n",
        "display(HTML(\"<p><h3>Choose the files to process:</h3>\"))\n",
        "display(HTML(\"<p><i>&nbsp&nbsp>>>>If you </i><b>Cancel upload</b><i> the previous files will be re-processed</p\"))\n",
        "\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def suppress_stdout():\n",
        "    \"\"\"Suppresses standard output within the context.\"\"\"\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = io.StringIO()\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        sys.stdout = old_stdout\n",
        "\n",
        "# Suppress standard output\n",
        "with suppress_stdout():\n",
        "  uploaded = files.upload(\"/content/MIDI Files/\")\n",
        "\n",
        "# Restore stdout\n",
        "#sys.stdout = old_stdout\n",
        "#print(\"Files uploaded successfully!\")\n",
        "\n",
        "if len (uploaded) > 0:\n",
        "  filenames = list(uploaded.keys())  # Extract uploaded filenames\n",
        "\n",
        "if len(filenames) < 1:\n",
        "  display(HTML(\"<p><h3>You did not choose any files - exiting.</h3>\"))\n",
        "  raise SystemExit\n",
        "\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Your list of items\n",
        "items = filenames\n",
        "\n",
        "# Create a SelectMultiple widget\n",
        "selector = widgets.SelectMultiple(\n",
        "    options=items,\n",
        "    value=[],  # Initially, nothing is selected\n",
        "    description='Reorder:',\n",
        "    rows=len(items),\n",
        "    layout=widgets.Layout(width='90%'),\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Create an Output widget to display the selected order\n",
        "output = widgets.Output()\n",
        "\n",
        "# Function to handle selection changes and update output\n",
        "def on_selection_change(change):\n",
        "    with output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Get newly selected items\n",
        "        newly_selected = [item for item in change['new'] if item not in change['old']]\n",
        "\n",
        "        # Move selected items to the bottom of the options list\n",
        "        current_options = list(selector.options)  # Get current options\n",
        "        for item in newly_selected:\n",
        "            if item in current_options:\n",
        "                #current_options.remove(item)  # Remove from current position\n",
        "                #current_options.append(item)  # Add to the end (bottom)\n",
        "                #current_options.insert(0, item)  # Insert at the beginning\n",
        "                current_index = current_options.index(item)\n",
        "                if current_index < len(current_options)-1:  # Check if it's not already at the top\n",
        "                    current_options.pop(current_index)  # Remove from current position\n",
        "                    current_options.insert(current_index + 1, item)  # Insert one position higher\n",
        "\n",
        "        selector.options = current_options  # Update widget options\n",
        "\n",
        "        # Display the current order\n",
        "        #print(\"Current Order:\")\n",
        "        #for i, item in enumerate(selector.options):\n",
        "        #    print(f\"{i+1}. {item}\")\n",
        "\n",
        "\n",
        "# Observe selection changes\n",
        "selector.observe(on_selection_change, names='value')\n",
        "\n",
        "display(HTML('<h3>Edit Processing Order</h3>You can edit the order in which the files will be processed.  Clicking a filename moves it downwards.'))\n",
        "\n",
        "# Display widgets\n",
        "display(selector, output)\n",
        "\n",
        "\n",
        "#####################################################################\n",
        "#  PROCESS THE MIDI FILES\n",
        "\n",
        "# These now inited at open of session\n",
        "#smoothness = 1\n",
        "#duration = 3 # Duration of the sound in seconds\n",
        "\n",
        "\n",
        "# Function to process the selected order (triggered by a button or other event)\n",
        "def process_order():\n",
        "    global filenames, smoothness, duration, histogram_checkbox_value, spectrum_checkbox_value, waveform_s_checkbox_value, waveform_f_checkbox_value, slider, slider2, smoothness_slider_value, image_list\n",
        "\n",
        "    # Hide the widgets\n",
        "    selector.layout.visibility = 'hidden'\n",
        "    process_button.layout.visibility = 'hidden'\n",
        "    spectrum_checkbox.layout.visibility = 'hidden'\n",
        "    histogram_checkbox.layout.visibility = 'hidden'\n",
        "    waveform_s_checkbox.layout.visibility = 'hidden'\n",
        "    waveform_f_checkbox.layout.visibility = 'hidden'\n",
        "    #output.layout.visibility = 'hidden' # If you want to hide the output as well\n",
        "\n",
        "    # Clear the output\n",
        "    clear_output()\n",
        "\n",
        "    displayed_order = list(selector.options)\n",
        "    # ... your processing logic here ...\n",
        "    #print(f\"Processing order: {displayed_order}\")\n",
        "    filenames = displayed_order\n",
        "\n",
        "    #when calculating the frequency fingerprint,\n",
        "    #the amplitude of the sine wave is raised to the power of *smoothness*\n",
        "    #Thus powers > 1 will polarize it more, making the higher values higher & the lower ones relatively deemphasized\n",
        "    #powers < will bring all amplitudes together in the center, all frequencies more even\n",
        "    smoothness_slider_value = slider.value  # Get the current value\n",
        "    smoothness = smoothness_slider_value/10 + 0.5\n",
        "\n",
        "    duration = slider2.value  # Get the current value\n",
        "\n",
        "    histogram_checkbox_value = histogram_checkbox.value\n",
        "    spectrum_checkbox_value = spectrum_checkbox.value\n",
        "    waveform_s_checkbox_value = waveform_s_checkbox.value\n",
        "    waveform_f_checkbox_value = waveform_f_checkbox.value\n",
        "\n",
        "    ####### start making a movie of the results\n",
        "    image_list = []\n",
        "\n",
        "\n",
        "    process_midi_files(filenames)\n",
        "\n",
        "# Create a button to trigger processing (optional)\n",
        "process_button = widgets.Button(description=\"Process Files\")\n",
        "process_button.on_click(lambda b: process_order())\n",
        "display(process_button)\n",
        "\n",
        "\n",
        "\n",
        "def process_midi_files(filenames):\n",
        "  # @title\n",
        "  # Parameters (you can change these as you like)\n",
        "  global duration, sample_rate  # Declare duration and sample_rate as global\n",
        "\n",
        "\n",
        "  #input_midi_file=\"https://www.classicalmidi.co.uk/5643rdpart.mid\"\n",
        "\n",
        "  big_signal = []\n",
        "\n",
        "  #for filename in uploaded.keys():\n",
        "  for filename in filenames:\n",
        "      #print(filename)\n",
        "      s=create_results(filename)\n",
        "      #ret = ret1.copy()\n",
        "      #s_max = np.max(np.abs(s))\n",
        "      #print (\"MAX \", s_max)\n",
        "      #s = np.array([(s/ np.max(np.abs(s))) * 0.9]) #normalizing it slightly soft, .7\n",
        "      big_signal.append(s)\n",
        "      #print (\"SAVEM\", len(big_signal), len (s), len(big_signal))\n",
        "      #signal_list.append(s)\n",
        "\n",
        "  display(HTML(\"<p><b>=========================================</b></p>\"))\n",
        "  display(HTML(\"<p><b>  ALL FREQUENCY FINGERPRINTS IN SEQUENCE</b></p>\"))\n",
        "  display(HTML(\"<p><b>=========================================</b></p>\"))\n",
        "  #print (len(big_signal[0]))\n",
        "  display(HTML(\"<p></p>\"))\n",
        "\n",
        "  #sigs = np.concatenate(big_signal)\n",
        "\n",
        "  sigs = big_signal[0]  # Start with the first signal\n",
        "  for i in range(1, len(big_signal)):\n",
        "    sigs=overlap_audio (sigs, big_signal[i], overlap_duration=duration/3, sr=44100)\n",
        "    #print (len(sigs))\n",
        "\n",
        "  fd = 0.1\n",
        "  if duration< 0.5:\n",
        "    fd = duration/40\n",
        "\n",
        "  sigs = fade_in_out_audio (sigs, fade_duration=fd, sr=sample_rate)\n",
        "\n",
        "  audio36 = Audio(data=sigs, rate=sample_rate, normalize=False)\n",
        "  display(audio36)\n",
        "\n",
        "  # Create a silent segment\n",
        "  #silence_duration = 200  # milliseconds\n",
        "  #silent_segment = AudioSegment.silent(duration=silence_duration)\n",
        "\n",
        "  #sigs = sigs.append(silent_segment, crossfade=0)\n",
        "\n",
        "\n",
        "  # Create an AudioFileClip from sigs directly\n",
        "  #audio_clip = AudioFileClip(io.BytesIO(sigs.tobytes()), fps=sample_rate, codec='pcm_s16le')\n",
        "  os.makedirs(\"/content/temp\", exist_ok=True)\n",
        "  temp_audio_filename = '/content/temp/temp_audio.wav'  # Temporary filename\n",
        "\n",
        "  sigs = add_silent_audio (sigs, duration=1, sr=44100)\n",
        "  sf.write(temp_audio_filename, sigs, samplerate=sample_rate)\n",
        "\n",
        "  # Now use the temporary filename with AudioFileClip\n",
        "  audio_clip = AudioFileClip(temp_audio_filename)\n",
        "\n",
        "  # ... (rest of the function) ...\n",
        "  from PIL import Image\n",
        "  #im = Image.fromarray(arr)\n",
        "  #im.save(\"your_file.jpeg\")\n",
        "\n",
        "  #Image.fromarray(image_list[0]).save('/content/first_image.png')\n",
        "  #Image.fromarray(image_list[1]).save('/content/first1_image.png')\n",
        "  #Image.fromarray(image_list[2]).save('/content/first2_image.png')\n",
        "  ##########Make the MOVIE\n",
        "\n",
        "  # Set a reasonable FPS (e.g., 25)\n",
        "  fps = 60\n",
        "\n",
        "  total_images = fps * (audio_clip.duration - 1) # -1 because we added 1 second of silence just above\n",
        "\n",
        "  # Duplicate images in the list\n",
        "  #repeated_image_list = [img for img in image_list for _ in range(repeat_count)]\n",
        "  # Calculate base repeat count using integer division\n",
        "  base_repeat_count = int( total_images // len(image_list))\n",
        "\n",
        "  # Calculate remaining frames\n",
        "  remaining_frames = total_images % len(image_list)\n",
        "\n",
        "  repeated_image_list = []\n",
        "  for i, image in enumerate(image_list):\n",
        "      # Repeat image base_repeat_count times\n",
        "      repeated_image_list.extend([image] * base_repeat_count)\n",
        "      # Add an extra frame if within remaining_frames\n",
        "      if i < remaining_frames:\n",
        "          repeated_image_list.append(image)\n",
        "\n",
        "    #repeated_image_list = image_list\n",
        "  last_img = image_list[-1]\n",
        "  repeated_image_list.extend([last_img] * fps) # add 1 second extra frames @ end\n",
        "\n",
        "\n",
        "  #audio_clip = concatenate_audioclips([audio_clip, silence_clip])\n",
        "\n",
        "\n",
        "  # Calculate duration in seconds\n",
        "  audio_duration = audio_clip.duration\n",
        "  #clip = ImageSequenceClip(repeated_image_list, fps=fps).set_duration(audio_duration).set_audio(audio_clip)\n",
        "  clip = ImageSequenceClip(repeated_image_list, fps=fps).set_audio(audio_clip)\n",
        "\n",
        "  #clip2 =ImageClip(image_list[0]).set_duration(5)\n",
        "  # Use repeated_image_list\n",
        "  #clip.list_images = repeated_image_list  # Update list_images\n",
        "  #clip.duration = len(repeated_image_list) / clip.fps  # Update duration\n",
        "  #audio_clip.duration = clip.duration  # Ensure audio and video have the same duration\n",
        "  #clip.set_audio(audio_clip)\n",
        "\n",
        "  # (Optional) clean up the temp file\n",
        "  #os.remove(temp_audio_filename)\n",
        "\n",
        "  video_tmp = '/content/all_fingerprints_movie.mp4'\n",
        "  clip.write_videofile(video_tmp, codec='libx264', audio_codec='aac', fps = fps)  # Save video\n",
        "\n",
        "  # Define a function to trigger the download\n",
        "  def download_movie(b):\n",
        "    #display(FileLink('/content/all_fingerprints_movie.mp4'))\n",
        "    files.download(video_tmp)\n",
        "\n",
        "  download_button = widgets.Button(description=\"Download Movie\")\n",
        "  download_button.on_click(download_movie)  # Attach the download function\n",
        "\n",
        "  # Display the button\n",
        "  display(download_button)\n",
        "\n",
        "  '''\n",
        "  video_tmp2 = '/content/all_fingerprints_movie2.mp4'\n",
        "  clip2.write_videofile(video_tmp2, codec='libx264', audio_codec='aac', fps = fps)  # Save video without audio\n",
        "  '''\n",
        "\n",
        "\n",
        "  #video_tag = f'<video width=\"640\" height=\"480\" controls><source src=\"all_fingerprints_movie.mp4\" type=\"video/mp4\"></video>'\n",
        "  #display(HTML(video_tag))  # Display the video within the cell\n",
        "\n",
        "  display(Video('all_fingerprints_movie.mp4', embed=True, width=640, height=480))\n",
        "\n",
        "  video_tmp2 = '/content/all_fingerprints.gif'\n",
        "  clip.write_gif(video_tmp2, fps=24)\n",
        "  # Define a function to trigger the download\n",
        "  def download_movie2(b):\n",
        "\n",
        "    files.download(video_tmp2)\n",
        "\n",
        "  # Create a download button using ipywidgets\n",
        "\n",
        "  download_button2 = widgets.Button(description=\"Download GIF\")\n",
        "  download_button2.on_click(download_movie2)  # Attach the download function\n",
        "\n",
        "  # Display the button\n",
        "  display(download_button2)\n",
        "\n",
        "  display(HTML(\"<p><b>=======END OF RESULTS===========================================================================================</b></p>\"))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QIyQCV3QOuQG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558,
          "referenced_widgets": [
            "68af2afeb8a84fc8a5ac8b0889ce5212",
            "196db286acf8427aa2cf4807f7b0d52b",
            "b6b793c10b52437aadbbf56f2f05221d",
            "d16206279d2b4fb79e745b96f3f00bce",
            "c2b08b775dbd4b098c54fa6476486c10",
            "4a5eee04e8e849a7bf95a6486ce3e2a3",
            "b5ea5583545141bebd073ee8c0dd484c",
            "947c17933fba4b43bbcc49608d400251",
            "0945f3d0450c4a0f890e215bd80cf7fb",
            "85b2d17fb9444b818e4c67ab00676c50",
            "7640c7a9bf6446d1a17e5ed71ed9168a",
            "b0fcbf28493b4758907e47c14785078a",
            "a337bea9d7294fb6bcff5e3c987f2084",
            "8314ed15a9a54e06a7c06ee550b0a9c7",
            "932e6e0074054992a558328a36b99a0b",
            "d8f26ea1cfcf4584a9db0b2b10c78c56",
            "aa98f2271401474e848151b1ddad4017",
            "dfcb8168b4e84f608ecde5fbd18fd95a",
            "38121b260ab843ce83c69e12b4b86a56",
            "03d0c4f3020b48b0ae8eac3f5891037c",
            "89a29d505ce94903bda5008816265ca7",
            "8d44eb83e3f04c939e2c235334e1ff58",
            "73176a9237804d1186bf82c1153138de",
            "c16b2d650e174665bc702966aaad61cb",
            "cf954f43b0be4022ae8a7c0319a964b1",
            "d094ec8db0a14f7998e55706a04116b6",
            "ee120c5e150044449ab9e8eb67b19aea",
            "1f1a11957d644e9e908297649906c4e6",
            "82386177b3e84e7db6c6bee2b6c3d63e",
            "bc3883039ae442459a6d426ef3dc584f",
            "d8d5d0565af1487fa6f6bdd385aed1ec",
            "473f808929e84fcfb8e0aa13428008ec",
            "4a4efd797c70421bb72fe6c61d2b4261"
          ]
        },
        "outputId": "ce4e5657-4d67-4b73-afca-abe329be8752",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p><h3>Choose which elements to display:</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Checkbox(value=True, description='Show Histogram of Pitch Tallies', layout=Layout(width='800px'"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68af2afeb8a84fc8a5ac8b0889ce5212"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p><h3>Fine-tune the sound:</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(FloatSlider(value=38.2, description='Smoothness:', layout=Layout(width='80%'), min=-5.0, readou"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfcb8168b4e84f608ecde5fbd18fd95a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p><h3>Choose the length of the fingerprint (seconds):</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(FloatSlider(value=0.35, description='Length:', layout=Layout(width='80%'), max=10.05, min=0.05,"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d094ec8db0a14f7998e55706a04116b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p><h3>Choose the files to process:</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p><i>&nbsp&nbsp>>>>If you </i><b>Cancel upload</b><i> the previous files will be re-processed</p"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e2e4d0c3-ecd7-4f95-9dbe-057f912d5ec2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e2e4d0c3-ecd7-4f95-9dbe-057f912d5ec2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentation, Background, and Credits"
      ],
      "metadata": {
        "id": "JLLZppouZfBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frequency Fingerprints results - what you are hearing and seeing\n",
        "\n",
        "\n",
        "*   For each MIDI file you upload, these results are shown:\n",
        " * **Average pitch** - calculated two ways: A simple count of notes played, or a weighted count taking into consideration how long the note was held\n",
        " * **Most commonly played note**\n",
        " * **A control box to play the sound file of the Frequency Fingerprint.** You can play the sound from your browser, or click the three dots menu to save the file.\n",
        " * **Right below the Fingerprint control, a link to download/play the MIDI file.** It is often instructive to go back and forth between listening to the Fingerprint and the actual music file.\n",
        " * **A graphical display of the Frequency Fingerprint** showing relative frequency of each note played in the MIDI file.  This is also the frequency graph (Fourier Transform) of the Frequency Fingerprint sound. See below for more info.\n",
        " * **A histogram showing the exact frequency of each pitch (note) in the work**\n",
        " * **A graph showing a short snippet of the waveform of of the Fingerprint**\n",
        "*   At the very end of the output is **a longer sound file playing the Frequency Fingerprints for each of your MIDI files in sequence.**\n",
        "\n",
        "You can choose checkboxes to omit any of the graphs from the output.\n",
        "\n",
        "You can use a slider to fine-tune the sound of the Frequency Fingerprints.  The slider controls how much prominent notes are emphasized or de-emphasized in comparison to other notes. With slider settings greater than 1, you hear only the most prominent notes and others are de-emphasized.  Some find this result is more harmonious.\n",
        "\n",
        "### How a Frequency Fingerprint sound file and graph are created\n",
        "The code simply tallies each note played in the MIDI file - including how long it was held.\n",
        "\n",
        "The result is a long list of every note from A0 to C8 and a total of how many times it was played - or more precisely, how much time in total each note was played.\n",
        "\n",
        "Those values are then interpreted as sound frequencies - each frequency being louder or softer in proportion to how many times that note was played.\n",
        "\n",
        "The Frequency Fingerprint sound file is created by creating a tone at each of those frequencies.  The tone is very loud for the notes that were played a lot, soft for those notes played less frequently, and silent for any notes never played.  All those tones are then combined - played all together at once - to create the Frequency Fingerprint sound file.\n",
        "\n",
        "We can then take that sound and analyze its frequencies. That is the graphical version of the Frequency Fingerprint that you see.\n",
        "\n",
        "### What is the waveform?\n",
        "The waveform shown is simply a graph showing short snippet of the Frequency Fingerprint sound's waveform.\n",
        "\n",
        "It is zoomed in to show a very short time interval, so that you can see the details of the waveform more clearly.\n",
        "\n",
        "### What the Frequency Fingerprint tells you and why it is interesting\n",
        "A Frequency Fingerprint is interesting on its own and gives you some high-level insight into a piece of music.\n",
        "\n",
        "Which notes are played more often?  Which are never played?  Which areas of the sound spectrum are used most often, and which rarely or never?\n",
        "\n",
        "In particular, there is almost always one note - occasionally two or three - that is clearly played far more often than the others.  Then there is a group of 3-4 notes just below that, and then 8-12 notes below those. So of all the musical notes there are, usually just a handful play the most important roles in any piece.\n",
        "\n",
        "In tonal musical styles, you can usually pick out the dominant (5th degree of the scale) which is almost always the most frequenctly played note, and the tonic (1st degree of the scale).  \n",
        "\n",
        "In other musical styles, the frequency at which various notes are played can give insight into which scales or tonal schemes are being used, and which notes within them are playing the most important roles.\n",
        "\n",
        "You will note that the human vocal range is generally where most notes in most musical styles are located.  It is interesting to see which exact areas of the pitch spectrum are being used in a particular work\n",
        "\n",
        "For example, some works will focus more in the lower (tenor or baritone) range, while others are more centered on Middle C, and others more focused on the upper/soprano ranges. And it is very common to see a bifurcation: Heavy emphasis on bass - often quite low bass - and then in the soprano region.\n",
        "\n",
        "Which tessatura or tessaturas a particular piece focuses on is, again, one of the most basic facts about the piece that shapes our perception and reception of it.\n",
        "\n",
        "So these basic facts and statistics about the pitches used in a work is very, very basic information about any musical work - but for that very reason, the insights from seeing and hearing the Frequency Fingerprint can be pretty profound.  Before the advent of computers, it was not easy to calculate or view such basic information about a piece.\n",
        "\n",
        "In addition, the sonic version of the Frequency Fingerprint gives a way to instantly grasp and perceive a kind of summary of the entire work.\n",
        "\n",
        "## Analyzing several pieces or movements\n",
        "\n",
        "The Frequency Fingerprint is and interesting and useful concept on its own.  But comparing the Fingerprints of different music is even more revealing.\n",
        "\n",
        "You can generate and compare Fingerprints for different movements of a single work, different sections within a single work, different pieces by the same composer, works of different composers, and works of different styles and time periods.\n",
        "\n",
        "For example, listening to (and viewing) the Fingerprint of each movement of a symphony, suite, sonata, set of pieces, tracks on a recording, or other works meant to be heard in succession is often very insightful.\n",
        "\n",
        "Viewing the fingerprints of different sections of a work can also be insightful: For example, breaking a sonata form movement into different MIDI files for exposition, development, and recapitulation can yield interesting insights.  Other subdivisions are possible as well: First theme, second theme, and so on.\n",
        "\n",
        "When you choose MIDI files for analysis in this software, you can choose several files at once. They will be processed in the order chosen.  You may need to rename the files, or re-sort your directory (for example, add 1, 2, 3, 4... to the beginning of the filenames, then sort the directory by name), so that the files are listed in order and will be processed in the order you wish.\n",
        "\n",
        "At the very end of the results, a sound file is created that plays all the Fingerprints of each file uploaded, in quick succession.  This is often the best way to get the overview of, for example, a multimovement work that is most helpful and insightful.\n",
        "\n",
        "## Why is does the Frequency Spectrum of the Frequency Footprint look different from the Histogram?\n",
        "\n",
        "The Histogram shows the exact count (of MIDI \"ticks\") corresponding to the length of time each musical note was played in the file.\n",
        "\n",
        "The Frequency Fingerprint audio file is created by adding together sine waves at the frequency of each note, with the amplitude (volume) determined by the corresponding value in the Historgram for that note.\n",
        "\n",
        "Then we make the Frequency Spectrum by taking a Fast Fourier Transform (FFT) of that audio file.  This shows each frequency and how strong it is.\n",
        "\n",
        "However, the FFT process is somewhat imperfect. It is a \"convolution algorithm\" that can approximate frequencies and amplitudes within certain limits depending on the length of the sound, number of sound samples available, and other factors. So it is a bit like translating an English sentence into four foreign languages in turn, then back to English.  In theory you will get the exact sentence back - in practice it is usually an approximation.\n",
        "\n",
        "In addition, very thin lines of the Spectrogram often disappear when the graph is reduced in size.  Click the graph for the full-sized version. In theory, because of the way the sound file was created, each peak of the Spectrogram is, literally, infinitely thin.  That means it is challenging to both measure and graph.\n",
        "\n",
        "And you will find moving the Tone Adjustment Slider significantly affects the look the Spectrogram - and the corresponding sound of the Fingerprint.  A value greater than one will \"polarize\" the results, strongly emphasizing the few notes with the highest tallies, and de-emphasizing those with lower tallies.  You will see this reflected in the Spectrogram.\n",
        "\n",
        "Moving the slider to values less than 1 will have the opposite effect: Note volumes are more equalized and all volumes are brought closer to the center. A value somewhere between 0.5 and 1 often makes the Histogram and Spectrogram *visually appear* the most similar.  You can hear a basic similarity to the sound through the whole range of the tone adjustment, however - so the difference is likely more in details about the appearance of the Spectrogram than in important difference in the sound itself.\n",
        "\n",
        "That is why both the Histogram and the Frequency Spectrum are displayed: The Histogram is exact in displaying the tally for each pitch. The Frequency Spectrum demonstrates how faithfully this data can be transformed into sound - that the result is, truly, startlingly good.\n",
        "\n",
        "But: If you are settling an argument with a friend about whether F#4 or C#3 was played more often in the Moonlight Sonata, it is best to consult the Histogram for the exact answer.\n",
        "\n",
        "### Example: Moonlight Sonata\n",
        "\n",
        "This software comes pre-loaded with a Fingerprint analysis of the three movements of Beethoven's Moonlight Sonata. You will be able to view and hear these Fingerprints simply by scrolling and viewing - before you run any code or upload files of your own.\n",
        "\n",
        "(If you can't see this analysis, you can easily create your own by searching online for MIDI files of the Moonlight - as three separate files for each movement - and then uploading and processing them according to the instructions above.)\n",
        "\n",
        "When you listen to and view the Moonlight Sonata Fingerprints, a few interesting facts become immediately apparent:\n",
        "\n",
        "* **The first movement has a low tessatura, the 2nd movement a middle tessatura, and the 3rd movement a higher tessatura.**\n",
        "\n",
        "The Moonlight is, famously, a sonata in which the first movement is slower tempo, the second movement moderate tempo, and the third movement fast tempo.\n",
        "\n",
        "The low, moderate, and high tessaturas of the three movements are just as obvious and just as important in supporting this scheme.  However, until you see the pitch content of a work summarized in this way, it is easy to miss.\n",
        "\n",
        "When you hear the Fingerprints of the three movements in succession, the progression low-medium-high frequency is very obvious.\n",
        "\n",
        "Looking at the average pitch for each movement is telling as well: Rising from E3 to B3 to C4.\n",
        "\n",
        "* **The frequency of notes played is telling**\n",
        "In each movement, G# stands out as a most frequently played note in several octaves.  This of course the dominant in each movement (1st movement c# minor, 2nd movement Db major - so Ab is the dominant; enharmonically G#, and 3rd movement c# minor).\n",
        "\n",
        "So the frequent use of the dominant tone is notable, and C#/Db is also very commonly used. You will note the different in frequency of E vs F in the various movements (E is far more common in the minor movements).  Altogether, you can garner a good deal of information about the tonality and scales used in the work, which pitches are more important and which less important, simply by looking at note frequences.\n",
        "\n",
        "* **Which note (and notes) dominate**\n",
        "It is interesting the degree to which a certain G#/Ab dominates each movement - note just F#s in general, but one particular F# in a particular octave.\n",
        "\n",
        "The 1st movement has just three notes with power above 1.5 (note Y axis scale) while the 2nd & 3rd movements have just one note each.\n",
        "\n",
        "Note how many notes are above power 1.5, 1.0, and 0.5 in each movement - the differences are quite telling.  The first movement very much concentrates on just three notes (G#1, C#2, G#2) and then three in a second tier. Whereas the other movements have one note in a tier of its own and 6-7 notes in a second tier.\n",
        "\n",
        "Again, these commonly-played notes tend to be important notes in the tonality of the work.\n",
        "\n",
        "With the Fingerprints, you can see and hear basic facts such at these at a glance - or a quick listen.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ppOAcqIFgBYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frequency Fingerprints - More details, background, credits\n",
        "\n",
        "### What the program does\n",
        "The Frequency Fingerprint totals up all the pitches of notes of the work, weighted by the number of times each note was played and how long it was held. You can then both hear and see the results. Average & most commonly played pitches are also shown.\n",
        "\n",
        "It then plays all notes of the entire piece simultaneously, with notes that were played more often throughout the work louder, less frequent notes/pitches softer, and notes/pitches never played completely silent.\n",
        "\n",
        "The result is a \"chord\" that sums up the entire piece - with notes of the chord louder or softer for more and less prominent notes of the work. You can listen to that chord below.\n",
        "\n",
        "Graphs showing the waveform and a Frequency Histogram of the Frequency Fingerprint are also shown below.\n",
        "\n",
        "In addition, the average pitch and weighted average pitch are calculated for each file.  (Average pitch counts only how many times each note is played, while weighted average also takes into account the duration each note is held. The Frequency Fingerprint also takes note duration into account.)\n",
        "\n",
        "### Why\n",
        "This project was spurred by a simple question by user u/oswaler on Reddit: *What is the average pitch in Beethoven's ninth symphony?*\n",
        "\n",
        "That is a simple yet quite profound question - and it is not very easy to find an accurate answer.  User u/CptanPanic came to the rescue with code to count the notes in a MIDI file and find the average pitch.\n",
        "\n",
        "I experimented with CptanPanic's code, and quickly realized it was possible to create a histogram of how often all notes up and down the frequency spectrum are played, and tally them into a big array.  Some of this was inspired by the [Humdrum Project](https://www.humdrum.org/), dedicated to creating tools for the computer analysis of music, which I have been following since the 1990s. For example, they have note-frequency histograms pre-calculated for a large number of works.\n",
        "\n",
        "Finally, while implementing the ideas above, I happend to see code by Max B. that provided a simple way to turn a list of frequencies and amplitudes into a sound file.  That kind of a list is, of course, exactly what the note frequency lists that we were creating from MIDI files are.  \n",
        "\n",
        "Putting all those ideas together is how Frequency Fingerprints were born.\n",
        "\n",
        "A similar idea involves starting with a music recording, analyzing the sound file for frequencies over time, creating a similar list of note frequencies with magnitudes measuring how prominent the note was throughout the work, and then producing a Frequency Fingerprint directly from that audio file.\n",
        "\n",
        "That project is underway with working code that provides as many or more interesting insights about an audio file as we are able to glean from the MIDI file.  See both the MIDI and Audio File versions of the code on the [Frequency Fingerprint Github Page](https://github.com/bhugh/FrequencyFingerprint).\n",
        "\n",
        "User u/oswaler was inspired in his question by movie buffs who have spent time computing the \"average color\" of movies.  This [can](https://moviepalette.com/) [be](https://www.wired.com/2014/09/cinema-is-evolving/#:~:text=Cutting%20is%20also%20investigating%20the,decades%20since%20color%20was%20introduced.) [done](https://www.instagram.com/movieluts/reel/C379x1CCaOx/) [a](https://happycoding.io/gallery/movie-colors/) [few](https://www.reddit.com/r/dataisbeautiful/comments/3rb8zi/the_average_color_of_every_frame_of_a_given_movie/) [different](https://thecolorsofmotion.com/) [ways](https://github.com/christianp05/average-color-of-frame) - and is both interesting and sometimes quite insightful. The Frequency Fingerprint it designed to be a similar concept for music and audio.\n",
        "\n",
        "In particular, taking the Fingerprint of different sections or movements of a work and then playing through them quickly in sequence, is closely analagous to the typical approach to average color, where the average color of a frame, or a few frames, is computed. These frames are then arranged sequentially like a spectrum.\n",
        "\n",
        "### Input files - MIDI\n",
        "The input source for creating a Frequency Fingerprint is a MIDI file - or several files, which are processed in sequence.  \n",
        "\n",
        "You can use this code to create Frequency Fingerprint of any musical work you like - any work for which a MIDI file is available. MIDI files for most works in the public domain are easily available - just search Google for \"*Composer - name of work* + MIDI\".\n",
        "\n",
        "So you can generate a Frequency Fingerprint for just about any musical work, piece, or song you like.\n",
        "\n",
        "As mentioned above, a parallel project will allow you to create a Frequency Fingerprint from any audio file.\n",
        "\n",
        "### Run the code here OR copy & experiment\n",
        "You can run the code and generate Frequency Fingerprints from MIDI files using the sandbox version of the software.  It is hosted on Google's Colab server.  You can view the documentation, code, and sample output anonymously, but to run the code and generate your own Frequency Fingerprints, you will need to log in with a google account.  Then you can run the notebook and generate Fingerprints as outlined in the instructions at the very top.\n",
        "\n",
        "You can also make a copy of the Notebook in your own Google Drive/Colab space (File/Save a Copy in Drive at the upper left).\n",
        "\n",
        "Another option is to download this code and run the script locally (Python).  You'll need to install python and at least a couple of packages (*pip install mido*, *apt install python3-pyaudio*). It will probably take some work to adapt the program to run standalone - but you are welcome to do so.\n",
        "\n",
        "### Credits & Resources\n",
        "\n",
        "- [Frequency Fingerprint Github Page](https://github.com/bhugh/FrequencyFingerprint)\n",
        "\n",
        "- The code to produce the waveform from frequencies and amplitudes was borrowed and modified from Max B. - https://www.kaggle.com/code/max398434434/generate-sound-from-frequencies-and-amplitudes\n",
        "\n",
        "- Code to parse the MIDI file and calculate average pitch of the file was borrowed and modified from u/CptanPanic - https://www.reddit.com/r/classicalmusic/comments/1gpcjtd/comment/lwqda\n",
        "\n",
        "- The [Humdrum Toolkit for computer analysis of music](https://www.humdrum.org/) and, particularly, [KernScores](https://kern.humdrum.org/), which collects electronic versions of many composers' scores in formats suitable for different types of analysis, and has a number of pre-calculated analyses - including text-format histograms of note frequency - available for many works.\n",
        "\n",
        "- This entire project was spurred by a question on r/ClassicalMusic by u/oswaler: https://www.reddit.com/r/classicalmusic/comments/1gpcjtd/what_is_the_average_pitch_in_beethovens_ninth/"
      ],
      "metadata": {
        "id": "F2Wz2u6aRa4b"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "tV3kcruKOcLa",
        "O1iLYIViOLK0",
        "cX1dZ124OGfw",
        "leHn2Q9Bpoou"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 6071335,
          "sourceId": 9886583,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 6072987,
          "sourceId": 9888819,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30527,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "68af2afeb8a84fc8a5ac8b0889ce5212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_196db286acf8427aa2cf4807f7b0d52b",
              "IPY_MODEL_b6b793c10b52437aadbbf56f2f05221d",
              "IPY_MODEL_d16206279d2b4fb79e745b96f3f00bce",
              "IPY_MODEL_c2b08b775dbd4b098c54fa6476486c10",
              "IPY_MODEL_4a5eee04e8e849a7bf95a6486ce3e2a3"
            ],
            "layout": "IPY_MODEL_b5ea5583545141bebd073ee8c0dd484c"
          }
        },
        "196db286acf8427aa2cf4807f7b0d52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Show Histogram of Pitch Tallies",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_947c17933fba4b43bbcc49608d400251",
            "style": "IPY_MODEL_0945f3d0450c4a0f890e215bd80cf7fb",
            "value": true
          }
        },
        "b6b793c10b52437aadbbf56f2f05221d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Show Power Spectrum Graph Rof Fingerprint",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_85b2d17fb9444b818e4c67ab00676c50",
            "style": "IPY_MODEL_7640c7a9bf6446d1a17e5ed71ed9168a",
            "value": false
          }
        },
        "d16206279d2b4fb79e745b96f3f00bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Show Waveform Segment of Fingerprint",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_b0fcbf28493b4758907e47c14785078a",
            "style": "IPY_MODEL_a337bea9d7294fb6bcff5e3c987f2084",
            "value": false
          }
        },
        "c2b08b775dbd4b098c54fa6476486c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Show Full Waveform of Fingerprint",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_8314ed15a9a54e06a7c06ee550b0a9c7",
            "style": "IPY_MODEL_932e6e0074054992a558328a36b99a0b",
            "value": false
          }
        },
        "4a5eee04e8e849a7bf95a6486ce3e2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8f26ea1cfcf4584a9db0b2b10c78c56",
            "placeholder": "",
            "style": "IPY_MODEL_aa98f2271401474e848151b1ddad4017",
            "value": "<p style=\"line-height: 1.1;\"><i>If you want to see in more detail how the Histogram is converted into the audible Fingerprint, you can check the options for the Power Spectrum and Waveforms of the Fingerprint</i></p>"
          }
        },
        "b5ea5583545141bebd073ee8c0dd484c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "0px 0px 0px 80px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "900px"
          }
        },
        "947c17933fba4b43bbcc49608d400251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "0945f3d0450c4a0f890e215bd80cf7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85b2d17fb9444b818e4c67ab00676c50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "7640c7a9bf6446d1a17e5ed71ed9168a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0fcbf28493b4758907e47c14785078a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "a337bea9d7294fb6bcff5e3c987f2084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8314ed15a9a54e06a7c06ee550b0a9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "800px"
          }
        },
        "932e6e0074054992a558328a36b99a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8f26ea1cfcf4584a9db0b2b10c78c56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa98f2271401474e848151b1ddad4017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfcb8168b4e84f608ecde5fbd18fd95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38121b260ab843ce83c69e12b4b86a56",
              "IPY_MODEL_03d0c4f3020b48b0ae8eac3f5891037c"
            ],
            "layout": "IPY_MODEL_89a29d505ce94903bda5008816265ca7"
          }
        },
        "38121b260ab843ce83c69e12b4b86a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "Smoothness:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8d44eb83e3f04c939e2c235334e1ff58",
            "max": 100,
            "min": -5,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".1f",
            "step": 0.1,
            "style": "IPY_MODEL_73176a9237804d1186bf82c1153138de",
            "value": 38.2
          }
        },
        "03d0c4f3020b48b0ae8eac3f5891037c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16b2d650e174665bc702966aaad61cb",
            "placeholder": "",
            "style": "IPY_MODEL_cf954f43b0be4022ae8a7c0319a964b1",
            "value": "<p style=\"line-height: 1.1;\"><i>Smoothness=0 is most realistic, keeping loudness of all pitches in exact proportion to the tally of notes as seen in the Histogram. Increasing Smoothness brings out the most prominent notes and de-emphasizes others - which is more to the point of a Frequency Fingerprint and often sounds better. </P><p style=\"line-height: 1.1;\">If you are getting phaser type effects increasing smoothness will reduce or eliminate them.</P><p style=\"line-height: 1.1;\">When fine-tuning a Fingerprint you can turn on the Fingerprint Power Spectrum and Waveform graphs to see how your changes are affecting the sound.</i></p>"
          }
        },
        "89a29d505ce94903bda5008816265ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "0px 0px 0px 80px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "900px"
          }
        },
        "8d44eb83e3f04c939e2c235334e1ff58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "73176a9237804d1186bf82c1153138de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "c16b2d650e174665bc702966aaad61cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf954f43b0be4022ae8a7c0319a964b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d094ec8db0a14f7998e55706a04116b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee120c5e150044449ab9e8eb67b19aea",
              "IPY_MODEL_1f1a11957d644e9e908297649906c4e6"
            ],
            "layout": "IPY_MODEL_82386177b3e84e7db6c6bee2b6c3d63e"
          }
        },
        "ee120c5e150044449ab9e8eb67b19aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "Length:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bc3883039ae442459a6d426ef3dc584f",
            "max": 10.05,
            "min": 0.05,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.05,
            "style": "IPY_MODEL_d8d5d0565af1487fa6f6bdd385aed1ec",
            "value": 0.35
          }
        },
        "1f1a11957d644e9e908297649906c4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_473f808929e84fcfb8e0aa13428008ec",
            "placeholder": "",
            "style": "IPY_MODEL_4a4efd797c70421bb72fe6c61d2b4261",
            "value": "<p style=\"line-height: 1.1;\"></p>"
          }
        },
        "82386177b3e84e7db6c6bee2b6c3d63e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "0px 0px 0px 80px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "900px"
          }
        },
        "bc3883039ae442459a6d426ef3dc584f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "d8d5d0565af1487fa6f6bdd385aed1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "473f808929e84fcfb8e0aa13428008ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4efd797c70421bb72fe6c61d2b4261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}